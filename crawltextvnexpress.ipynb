{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: newspaper3k in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (0.2.8)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (4.12.2)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (9.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.11 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (6.0)\n",
      "Requirement already satisfied: cssselect>=0.9.2 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (1.1.0)\n",
      "Requirement already satisfied: lxml>=3.6.0 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (4.9.3)\n",
      "Requirement already satisfied: nltk>=3.2.1 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (3.8.1)\n",
      "Requirement already satisfied: requests>=2.10.0 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (2.31.0)\n",
      "Requirement already satisfied: feedparser>=5.2.1 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (6.0.10)\n",
      "Requirement already satisfied: tldextract>=2.0.1 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (3.2.0)\n",
      "Requirement already satisfied: feedfinder2>=0.0.4 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (0.0.4)\n",
      "Requirement already satisfied: jieba3k>=0.35.1 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (0.35.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (2.8.2)\n",
      "Requirement already satisfied: tinysegmenter==0.3 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from newspaper3k) (0.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.4)\n",
      "Requirement already satisfied: six in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from requests>=2.10.0->newspaper3k) (2023.7.22)\n",
      "Requirement already satisfied: requests-file>=1.4 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
      "Requirement already satisfied: filelock>=3.0.8 in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from tldextract>=2.0.1->newspaper3k) (3.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\vanhu\\anaconda3\\lib\\site-packages (from click->nltk>=3.2.1->newspaper3k) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install newspaper3k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading \"brown\"\n",
      "Downloading \"punkt\"\n",
      "Downloading \"maxent_treebank_pos_tagger\"\n",
      "Downloading \"movie_reviews\"\n",
      "Downloading \"wordnet\"\n",
      "Downloading \"stopwords\"\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   657  100   657    0     0   1382      0 --:--:-- --:--:-- --:--:--  1386\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\vanhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vanhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_treebank_pos_tagger to\n",
      "[nltk_data]     C:\\Users\\vanhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_treebank_pos_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\vanhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vanhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vanhu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/codelucas/newspaper/master/download_corpora.py | python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup, Tag\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import requests\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = []\n",
    "for i in range(1, 3): \n",
    "    if i == 1:\n",
    "        link = 'https://vnexpress.net/kinh-doanh/chung-khoan'\n",
    "    else:\n",
    "        link = f'https://vnexpress.net/kinh-doanh/chung-khoan-p{i}'\n",
    "    response = requests.get(link)\n",
    "    soup.append(BeautifulSoup(response.content, \"html.parser\"))\n",
    "    #titles = soup.find_all('section', attrs={'class':'section section_container mt15'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://vnexpress.net/khoi-ngoai-ban-rong-phien-thu-6-lien-tiep-4685643.html', 'https://vnexpress.net/nha-dau-tu-gom-co-phieu-ldg-4685146.html', 'https://vnexpress.net/khoi-ngoai-quay-lung-voi-co-phieu-the-gioi-di-dong-4684781.html', 'https://vnexpress.net/lai-suat-trai-phieu-doanh-nghiep-van-nong-4684086.html', 'https://vnexpress.net/hon-39-trieu-co-phieu-ldg-treo-gia-san-4683637.html', 'https://vnexpress.net/vn-index-lai-giam-diem-o-nhung-phut-cuoi-4683207.html', 'https://vnexpress.net/them-doanh-nghiep-xin-khat-no-trai-phieu-4682829.html', 'https://vnexpress.net/vn-index-lay-lai-moc-1-100-diem-4682781.html', 'https://vnexpress.net/mot-sep-hah-ban-chui-co-phieu-vi-mat-kem-4682401.html', 'https://vnexpress.net/co-phieu-thep-nang-do-thi-truong-4682313.html', 'https://vnexpress.net/tien-vao-chung-khoan-giam-manh-4681866.html', 'https://vnexpress.net/cong-ty-bau-duc-huy-danh-sach-nha-dau-tu-sap-mua-130-trieu-co-phieu-4681125.html', 'https://vnexpress.net/chung-khoan-loi-nguoc-dong-tang-7-diem-4680949.html', 'https://vnexpress.net/dinh-gia-thi-truong-chung-khoan-viet-nam-khong-con-re-4680610.html', 'https://vnexpress.net/chung-khoan-lpbank-se-mua-co-phieu-cua-cong-ty-bau-duc-4680575.html', 'https://vnexpress.net/chung-khoan-lao-doc-cuoi-phien-4680508.html', 'https://vnexpress.net/co-hoi-nao-cho-co-phieu-nganh-tieu-dung-ban-le-4680279.html', 'https://vnexpress.net/co-phieu-cong-ty-cua-shark-thuy-bi-huy-niem-yet-4680120.html', 'https://vnexpress.net/co-phieu-the-gioi-di-dong-tiep-tuc-bi-khoi-ngoai-xa-hang-4680033.html', 'https://vnexpress.net/co-phieu-xay-dung-hoa-binh-tang-kich-tran-4679563.html', 'https://vnexpress.net/lanh-dao-nhieu-doanh-nghiep-sang-tay-hang-trieu-co-phieu-4679335.html', 'https://vnexpress.net/chung-khoan-bien-dong-manh-4679075.html', 'https://vnexpress.net/tong-giam-doc-hdbank-muon-mua-them-2-trieu-co-phieu-4679125.html', 'https://vnexpress.net/loat-lanh-dao-seabank-muon-ban-luong-lon-co-phieu-4678503.html', 'https://vnexpress.net/chung-khoan-lui-sau-4678192.html', 'https://vnexpress.net/chung-khoan-tro-lai-sac-xanh-trong-tich-tac-4677772.html', 'https://vnexpress.net/khoi-ngoai-dut-chuoi-ban-rong-4677323.html', 'https://vnexpress.net/co-phieu-ngan-hang-dan-dat-thi-truong-4676848.html', 'https://vnexpress.net/vietnam-airlines-tiep-tuc-hoan-hop-dai-hoi-co-dong-4676512.html', 'https://vnexpress.net/horea-ap-luc-tra-no-trai-phieu-nam-2024-se-len-muc-cao-nhat-ba-nam-4676093.html', 'https://vnexpress.net/yeu-to-tieu-cuc-toi-chung-khoan-co-the-da-qua-4675816.html', 'https://vnexpress.net/co-phieu-hoang-anh-gia-lai-loi-nguoc-dong-4675463.html', 'https://vnexpress.net/chuyen-gia-du-bao-nhung-co-phieu-co-the-tang-gia-nam-2024-4675115.html', 'https://vnexpress.net/co-phieu-vingroup-dong-loat-tang-manh-4675020.html', 'https://vnexpress.net/von-hoa-chung-khoan-tang-them-hang-ty-usd-4674560.html', 'https://vnexpress.net/chung-khoan-dao-chieu-4674083.html', 'https://vnexpress.net/400-000-tai-khoan-chung-khoan-dong-trong-mot-thang-4674068.html', 'https://vnexpress.net/co-phieu-ngan-hang-keo-vn-index-4673654.html', 'https://vnexpress.net/sep-hose-xin-thoi-chuc-de-di-du-hoc-4673166.html', 'https://vnexpress.net/ong-nguyen-duc-tai-dang-ky-mua-mot-trieu-co-phieu-mwg-4672936.html', 'https://vnexpress.net/co-phieu-the-gioi-di-dong-tang-manh-hai-phien-lien-tiep-4672706.html', 'https://vnexpress.net/chung-khoan-tang-manh-nhat-ke-tu-dau-nam-4672194.html', 'https://vnexpress.net/sac-xanh-tro-lai-chung-khoan-4671819.html', 'https://vnexpress.net/con-cua-sep-gao-trung-an-mua-ban-chui-co-phieu-4671416.html', 'https://vnexpress.net/chung-khoan-tiep-tuc-giam-manh-cuoi-phien-4671315.html', 'https://vnexpress.net/chung-khoan-lai-lao-doc-cuoi-phien-4670918.html', 'https://vnexpress.net/vo-chong-ong-tran-dinh-long-muon-chuyen-40-trieu-co-phieu-hoa-phat-cho-con-trai-4670001.html', 'https://vnexpress.net/chung-khoan-cai-thien-diem-so-sau-phien-rot-manh-4669938.html', 'https://vnexpress.net/nova-consumer-sap-len-san-upcom-4669907.html', 'https://vnexpress.net/vn-index-giam-manh-nhat-hai-thang-4669314-tong-thuat.html', 'https://vnexpress.net/co-phieu-phan-bon-lao-doc-4669061.html', 'https://vnexpress.net/co-phieu-cua-vng-lai-bi-han-che-giao-dich-4668720.html', 'https://vnexpress.net/tien-vao-chung-khoan-thap-nhat-gan-nua-nam-4668595.html', 'https://vnexpress.net/vn-index-lai-tuot-moc-1-100-diem-4668123.html', 'https://vnexpress.net/chung-khoan-loi-nguoc-dong-tang-20-diem-4667201.html', 'https://vnexpress.net/khach-san-hoang-anh-gia-lai-duoc-ban-cho-doanh-nghiep-chan-nuoi-4666794.html', 'https://vnexpress.net/han-chot-hon-mot-nghin-ma-trai-phieu-van-chua-niem-yet-4666584.html', 'https://vnexpress.net/vn-index-ve-muc-thap-nhat-hon-4-thang-4666768.html', 'https://vnexpress.net/chung-khoan-lai-giam-dot-ngot-sau-14h-4666322.html', 'https://vnexpress.net/vn-index-giam-20-diem-nhung-phut-cuoi-phien-4665888.html']\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "# for s in soup:\n",
    "#     for title in titles:    \n",
    "#         items = s.find_all('h2', class_='title-news')\n",
    "#         for item in items:\n",
    "#             link = item.find('a', class_='')\n",
    "#             if link and link.has_attr('href'):\n",
    "#                 links.append(link.attrs[\"href\"])\n",
    "for element in soup:\n",
    "    # Kiểm tra xem phần tử có phải là một Tag hợp lệ\n",
    "    if isinstance(element, Tag):\n",
    "        items = element.find_all('h2', class_='title-news')\n",
    "        for item in items:\n",
    "            link = item.find('a', class_='')\n",
    "            if link and link.has_attr('href'):\n",
    "                links.append(link.attrs[\"href\"])\n",
    "print(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách các từ khóa bạn quan tâm\n",
    "keys = [\"chứng khoán\"]\n",
    "\n",
    "# Hàm để kiểm tra xem một chuỗi có chứa bất kỳ từ khóa nào không\n",
    "def contains_keyword(text, keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword in text.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for link in links:\n",
    "    news = requests.get(link)\n",
    "    soup = BeautifulSoup(news.content, \"html.parser\")\n",
    "    \n",
    "     # Lấy tiêu đề\n",
    "    title_tag = soup.find('h1', class_='title-detail')\n",
    "    # title = title_tag.get_text().strip() if title_tag else None\n",
    "    title = title_tag.get_text().strip() if title_tag else \"\"\n",
    "\n",
    "    # Lấy tên tác giả\n",
    "    author_tag = soup.find('strong')\n",
    "    # author = author_tag.get_text().strip() if author_tag else None\n",
    "    author = author_tag.get_text().strip() if author_tag else \"\"\n",
    "\n",
    "    # Lấy thời gian đăng tải\n",
    "    time_tag = soup.find('span', class_='date')\n",
    "    # time = time_tag.get_text().strip() if time_tag else None\n",
    "    if time_tag:\n",
    "        time_full = time_tag.get_text().strip()\n",
    "        # Chia chuỗi dựa vào dấu phẩy và lấy phần ngày tháng\n",
    "        time_parts = time_full.split(',')\n",
    "        time = time_parts[1].strip() if len(time_parts) > 1 else None\n",
    "    else:\n",
    "        time = None\n",
    "\n",
    "    # Lấy mô tả\n",
    "    description_tag = soup.find('p', class_='description')  \n",
    "    # description = description_tag.get_text().strip() if description_tag else None\n",
    "    description = description_tag.get_text().strip() if description_tag else \"\"\n",
    "    \n",
    "    content_divs = soup.find_all('article', class_='fck_detail ')  # This returns a ResultSet\n",
    "\n",
    "    all_p_text = []\n",
    "    for div in content_divs:\n",
    "        p_tags = div.find_all('p', class_='Normal')\n",
    "        for p in p_tags:\n",
    "            text = p.get_text().strip()  \n",
    "            if text:  \n",
    "                all_p_text.append(text)\n",
    "    content = ' '.join(all_p_text) if all_p_text else \"\"\n",
    "    # article = Article(link, language='vi', request_timeout=10000)\n",
    "    # article.download()\n",
    "    # article.parse()\n",
    "    # content = str(article.text).replace(\"\\n\",\"\")\n",
    "    \n",
    "    # print(f\"Title: {title}, Author: {author}, Time: {time}, Description: {description}, Link: {link}\")#, Link: {link}\n",
    "    if contains_keyword(title + \" \" + description + \" \" + content, keys):\n",
    "        data.append([title, author, time, description, link])\n",
    "\n",
    "for i in range(len(data)):\n",
    "    url = data[i][-1]  # Giả sử URL là phần tử cuối cùng của mỗi hàng\n",
    "    data[i][-1] = f'=HYPERLINK(\"{url}\")'  # Tạo văn bản đặc biệt\n",
    "\n",
    "directory = 'data/csv/vnexpress'\n",
    "csv_file_path = f'{directory}/vnexpress.csv'\n",
    "# Tạo thư mục nếu nó chưa tồn tại\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Tạo DataFrame\n",
    "df = pd.DataFrame(data, columns=['Title', 'Author', 'Time', 'Description', 'Link'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(content)\n",
    "# print(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lưu dữ liệu vào file CSV: data/csv/vnexpress/vnexpress.csv\n"
     ]
    }
   ],
   "source": [
    "df.to_csv(csv_file_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Đã lưu dữ liệu vào file CSV: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm bạn đã cung cấp\n",
    "def create_and_write_file(directory, filename, content):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_path = os.path.join(directory, filename)\n",
    "    with open(file_path, 'w', encoding='utf-8-sig') as file:\n",
    "        file.write(content)\n",
    "\n",
    "keywords = [\"chứng khoán\"]\n",
    "\n",
    "def contains_keyword(text):\n",
    "    return any(keyword in text for keyword in keywords)\n",
    "\n",
    "def crawl_by_url(url, title):\n",
    "    article = Article(url, language='vi', request_timeout=10000)\n",
    "    article.download()\n",
    "    article.parse()\n",
    "    contents = str(article.text).replace(\"\\n\",\"\")\n",
    "    article.nlp()\n",
    "    # replace\n",
    "    char_to_replace = {':': '',\n",
    "                       '/': '',\n",
    "                       '\\\\': '',\n",
    "                      '*': '',\n",
    "                      '?': '',\n",
    "                      '\"': '',\n",
    "                      '<': '',\n",
    "                      '>': '',\n",
    "                      '|': ''}\n",
    "    for key, value in char_to_replace.items():\n",
    "        # Replace key character with value character in string\n",
    "        title = title.replace(key, value)\n",
    "\n",
    "    # write txt\n",
    "    # https://vnexpress.net\n",
    "    # if((url.find('https://vnexpress.net/') != -1)):\n",
    "    #     directory = \"data/text/vnexpress\"\n",
    "    #     output = title + \".txt\"\n",
    "    #     content = title + \"\\n\" + contents\n",
    "\n",
    "    # create_and_write_file(directory, output, content)\n",
    "    \n",
    "    if contains_keyword(title.lower()) or contains_keyword(contents.lower()):\n",
    "        # Tiến hành lưu file nếu có từ khóa\n",
    "        directory = \"data/text/vnexpress\"\n",
    "        output = title + \".txt\"\n",
    "        content = title + \"\\n\" + contents\n",
    "        create_and_write_file(directory, output, content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VNEXPRESS\n",
    "def get_links_in_page_vnexpress(url):\n",
    "    page = urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    # <section>\n",
    "    sections = soup.find_all('section', attrs={'class':'section section_container mt15'})\n",
    "    results = []\n",
    "    links = []\n",
    "    # <h3>\n",
    "    h3_all = []\n",
    "    for section in sections:\n",
    "        h3_all.extend(section.find_all('h2', attrs={'class':'title-news'}))\n",
    "    # <a>\n",
    "    a_all = []\n",
    "    results = [[]]\n",
    "    for h3 in h3_all:\n",
    "        a_all.extend(h3.find_all('a', attrs={'class':''}))\n",
    "    for a in a_all:\n",
    "        title = a.get('title')\n",
    "        link = a.get('href')\n",
    "        print(f'Title: {title} - Link: {link}')\n",
    "        results.append([title,link])\n",
    "        # links.append(link)\n",
    "    return results\n",
    "\n",
    "# base_url = 'https://vnexpress.net/kinh-doanh/chung-khoan'\n",
    "# all_links = get_links_in_page_vnexpress(base_url)\n",
    "\n",
    "# # Lưu vào danh sách links\n",
    "# links = all_links[:2] \n",
    "# print(links)# Lấy 2 link đầu tiên\n",
    "# get_links_in_page_vnexpress('https://vnexpress.net/kinh-doanh/chung-khoan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VNEXPRESS\n",
    "def get_page_urls_vnexpress(base_url, quantity):\n",
    "    news_per_page = 30\n",
    "    if quantity % news_per_page == 0:\n",
    "        no_of_pages = quantity // news_per_page\n",
    "    else:\n",
    "        no_of_pages = quantity // news_per_page + 1\n",
    "\n",
    "    extend_url = ['-p{}'.format(page) for page in range(2, no_of_pages + 1)]\n",
    "    url_list = [base_url + extend_part for extend_part in extend_url]\n",
    "    url_list.insert(0, base_url)\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def vnexpress(base_url):\n",
    "#     page_urls = get_page_urls_vnexpress(base_url, quantity=2)\n",
    "# #     print(page_urls)\n",
    "#     # total_articles = 0\n",
    "#     all_data = []\n",
    "#     for page in page_urls:\n",
    "#         arr = get_links_in_page_vnexpress(page)\n",
    "#         if arr:\n",
    "#             all_data.extend(arr)\n",
    "#         if arr is not None:\n",
    "#             for i in range(1,len(arr)-1):\n",
    "#                 title = arr[i][0]\n",
    "#                 url = arr[i][1]\n",
    "#                 crawl_by_url(url,title)\n",
    "    \n",
    "def vnexpress(base_url):\n",
    "    page_urls = get_page_urls_vnexpress(base_url, quantity=2)\n",
    "    total_articles = 0  # Biến đếm số lượng bài viết\n",
    "    max_articles = 22  # Giới hạn số lượng bài viết tối đa\n",
    "\n",
    "    for page in page_urls:\n",
    "        if total_articles >= max_articles:\n",
    "            break  # Dừng nếu đã đạt số lượng tối đa\n",
    "\n",
    "        arr = get_links_in_page_vnexpress(page)\n",
    "        if arr is not None:\n",
    "            for i in range(1, len(arr) - 1):\n",
    "                if total_articles >= max_articles:\n",
    "                    break  # Kiểm tra lại trong vòng lặp\n",
    "\n",
    "                title = arr[i][0]\n",
    "                url = arr[i][1]\n",
    "                crawl_by_url(url, title)\n",
    "                total_articles += 1  # Tăng biến đếm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Nhà đầu tư gom cổ phiếu LDG - Link: https://vnexpress.net/nha-dau-tu-gom-co-phieu-ldg-4685146.html\n",
      "Title: Khối ngoại 'quay lưng' với cổ phiếu Thế Giới Di Động - Link: https://vnexpress.net/khoi-ngoai-quay-lung-voi-co-phieu-the-gioi-di-dong-4684781.html\n",
      "Title: Lãi suất trái phiếu doanh nghiệp vẫn nóng - Link: https://vnexpress.net/lai-suat-trai-phieu-doanh-nghiep-van-nong-4684086.html\n",
      "Title: Hơn 39 triệu cổ phiếu LDG treo giá sàn - Link: https://vnexpress.net/hon-39-trieu-co-phieu-ldg-treo-gia-san-4683637.html\n",
      "Title: VN-Index lại giảm điểm ở những phút cuối - Link: https://vnexpress.net/vn-index-lai-giam-diem-o-nhung-phut-cuoi-4683207.html\n",
      "Title: Thêm doanh nghiệp xin khất nợ trái phiếu - Link: https://vnexpress.net/them-doanh-nghiep-xin-khat-no-trai-phieu-4682829.html\n",
      "Title: VN-Index lấy lại mốc 1.100 điểm - Link: https://vnexpress.net/vn-index-lay-lai-moc-1-100-diem-4682781.html\n",
      "Title: Một sếp HAH bán chui cổ phiếu 'vì mắt kém' - Link: https://vnexpress.net/mot-sep-hah-ban-chui-co-phieu-vi-mat-kem-4682401.html\n",
      "Title: Cổ phiếu thép nâng đỡ thị trường - Link: https://vnexpress.net/co-phieu-thep-nang-do-thi-truong-4682313.html\n",
      "Title: Tiền vào chứng khoán giảm mạnh - Link: https://vnexpress.net/tien-vao-chung-khoan-giam-manh-4681866.html\n",
      "Title: Công ty Bầu Đức hủy danh sách nhà đầu tư sắp mua 130 triệu cổ phiếu - Link: https://vnexpress.net/cong-ty-bau-duc-huy-danh-sach-nha-dau-tu-sap-mua-130-trieu-co-phieu-4681125.html\n",
      "Title: Chứng khoán lội ngược dòng tăng 7 điểm - Link: https://vnexpress.net/chung-khoan-loi-nguoc-dong-tang-7-diem-4680949.html\n",
      "Title: 'Định giá thị trường chứng khoán Việt Nam không còn rẻ' - Link: https://vnexpress.net/dinh-gia-thi-truong-chung-khoan-viet-nam-khong-con-re-4680610.html\n",
      "Title: Chứng khoán LPBank sẽ mua cổ phiếu của Công ty bầu Đức - Link: https://vnexpress.net/chung-khoan-lpbank-se-mua-co-phieu-cua-cong-ty-bau-duc-4680575.html\n",
      "Title: Chứng khoán lao dốc cuối phiên - Link: https://vnexpress.net/chung-khoan-lao-doc-cuoi-phien-4680508.html\n",
      "Title: Cơ hội nào cho cổ phiếu ngành tiêu dùng bán lẻ? - Link: https://vnexpress.net/co-hoi-nao-cho-co-phieu-nganh-tieu-dung-ban-le-4680279.html\n",
      "Title: Cổ phiếu công ty của Shark Thủy bị hủy niêm yết - Link: https://vnexpress.net/co-phieu-cong-ty-cua-shark-thuy-bi-huy-niem-yet-4680120.html\n",
      "Title: Cổ phiếu Thế Giới Di Động tiếp tục bị khối ngoại xả hàng - Link: https://vnexpress.net/co-phieu-the-gioi-di-dong-tiep-tuc-bi-khoi-ngoai-xa-hang-4680033.html\n",
      "Title: Cổ phiếu Xây dựng Hòa Bình tăng kịch trần - Link: https://vnexpress.net/co-phieu-xay-dung-hoa-binh-tang-kich-tran-4679563.html\n",
      "Title: Lãnh đạo nhiều doanh nghiệp sang tay hàng triệu cổ phiếu - Link: https://vnexpress.net/lanh-dao-nhieu-doanh-nghiep-sang-tay-hang-trieu-co-phieu-4679335.html\n",
      "Title: Chứng khoán biến động mạnh - Link: https://vnexpress.net/chung-khoan-bien-dong-manh-4679075.html\n",
      "Title: Tổng giám đốc HDBank muốn mua thêm 2 triệu cổ phiếu - Link: https://vnexpress.net/tong-giam-doc-hdbank-muon-mua-them-2-trieu-co-phieu-4679125.html\n",
      "Title: Loạt lãnh đạo SeABank muốn bán lượng lớn cổ phiếu - Link: https://vnexpress.net/loat-lanh-dao-seabank-muon-ban-luong-lon-co-phieu-4678503.html\n",
      "Title: Chứng khoán lùi sâu - Link: https://vnexpress.net/chung-khoan-lui-sau-4678192.html\n",
      "Title: Chứng khoán trở lại sắc xanh trong tích tắc - Link: https://vnexpress.net/chung-khoan-tro-lai-sac-xanh-trong-tich-tac-4677772.html\n",
      "Title: Khối ngoại dứt chuỗi bán ròng - Link: https://vnexpress.net/khoi-ngoai-dut-chuoi-ban-rong-4677323.html\n",
      "Title: Cổ phiếu ngân hàng dẫn dắt thị trường - Link: https://vnexpress.net/co-phieu-ngan-hang-dan-dat-thi-truong-4676848.html\n",
      "Title: Vietnam Airlines tiếp tục hoãn họp đại hội cổ đông - Link: https://vnexpress.net/vietnam-airlines-tiep-tuc-hoan-hop-dai-hoi-co-dong-4676512.html\n",
      "Title: HoREA: Áp lực trả nợ trái phiếu năm 2024 sẽ lên mức cao nhất ba năm - Link: https://vnexpress.net/horea-ap-luc-tra-no-trai-phieu-nam-2024-se-len-muc-cao-nhat-ba-nam-4676093.html\n",
      "Title: 'Yếu tố tiêu cực tới chứng khoán có thể đã qua' - Link: https://vnexpress.net/yeu-to-tieu-cuc-toi-chung-khoan-co-the-da-qua-4675816.html\n"
     ]
    }
   ],
   "source": [
    "vnexpress('https://vnexpress.net/kinh-doanh/chung-khoan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có 21 file .txt trong thư mục C:\\Users\\vanhu\\Desktop\\Crawlnews\\crawling-VietNam-News\\data\\text\\vnexpress.\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\vanhu\\Desktop\\Crawlnews\\crawling-VietNam-News\\data\\text\\vnexpress\"\n",
    "import os\n",
    "\n",
    "def count_txt_files(directory):\n",
    "    # Đảm bảo thư mục tồn tại\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"Thư mục không tồn tại.\")\n",
    "        return 0\n",
    "\n",
    "    # Đếm số file .txt\n",
    "    count = 0\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            count += 1\n",
    "\n",
    "    return count\n",
    "\n",
    "# Ví dụ sử dụng\n",
    "num_txt_files = count_txt_files(path)\n",
    "print(f\"Có {num_txt_files} file .txt trong thư mục {path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
